# -*- coding: utf-8 -*-
"""Market Data Client - yfinanceë¥¼ ì‚¬ìš©í•œ ì‹œì¥ ë°ì´í„° ì¡°íšŒ (ìºì‹± ì „ë‹´)"""
import os
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

import pandas as pd
import yfinance as yf
import logging

logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
DATA_DIR = os.path.join(PROJECT_ROOT, "data", "market_cache")
os.makedirs(DATA_DIR, exist_ok=True)


@dataclass
class CacheInfo:
    """ìºì‹œ ë©”íƒ€ë°ì´í„°"""
    cached_at: str  # ISO í˜•ì‹ íƒ€ì„ìŠ¤íƒ¬í”„
    elapsed_hours: float  # ìºì‹œ ê²½ê³¼ ì‹œê°„
    is_from_cache: bool  # ìºì‹œì—ì„œ ê°€ì ¸ì™”ëŠ”ì§€ ì—¬ë¶€


@dataclass
class TickerData:
    """í‹°ì»¤ ë°ì´í„° (ìºì‹œ ì •ë³´ í¬í•¨)"""
    df: pd.DataFrame
    cache_info: CacheInfo


class MarketDataClient:
    """ì‹œì¥ ë°ì´í„° ì¡°íšŒ í´ë¼ì´ì–¸íŠ¸ (yfinance ì‚¬ìš©, ìºì‹± ì „ë‹´)"""

    def __init__(self):
        # ì§€ì—° importë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
        from config import key_store
        self._key_store = key_store

    def _get_cache_info(self, timestamp_key: str, cache_hours: int) -> Optional[CacheInfo]:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸ ë° CacheInfo ë°˜í™˜

        Args:
            timestamp_key: íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥ í‚¤
            cache_hours: ìºì‹œ ìœ íš¨ ì‹œê°„

        Returns:
            CacheInfo if ìºì‹œ ìœ íš¨, None if ìºì‹œ ë§Œë£Œ/ì—†ìŒ
        """
        cached_timestamp = self._key_store.read(timestamp_key)
        if not cached_timestamp:
            return None

        try:
            cached_time = datetime.fromisoformat(cached_timestamp)
            elapsed_hours = (datetime.now() - cached_time).total_seconds() / 3600

            if elapsed_hours < cache_hours:
                return CacheInfo(
                    cached_at=cached_timestamp,
                    elapsed_hours=round(elapsed_hours, 2),
                    is_from_cache=True
                )
            else:
                logger.info(f"ğŸ“¥ ìºì‹œ ë§Œë£Œ (ê²½ê³¼: {elapsed_hours:.1f}ì‹œê°„ > {cache_hours}ì‹œê°„)")
                return None
        except (ValueError, TypeError) as e:
            logger.warning(f"âš ï¸ íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def _save_cache_timestamp(self, timestamp_key: str) -> str:
        """í˜„ì¬ ì‹œê°„ì„ ìºì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì €ì¥

        Returns:
            ì €ì¥ëœ ISO í˜•ì‹ íƒ€ì„ìŠ¤íƒ¬í”„
        """
        now = datetime.now().isoformat()
        self._key_store.write(timestamp_key, now)
        return now

    def fetch_ticker_history(
        self,
        ticker: str,
        interval: int = 30,
        cache_hours: int = 6
    ) -> Optional[TickerData]:
        """
        íŠ¹ì • í‹°ì»¤ì˜ ê³¼ê±° ë°ì´í„° ì¡°íšŒ (CSV + íƒ€ì„ìŠ¤íƒ¬í”„ ìºì‹±)

        Args:
            ticker: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: 'TQQQ', 'SOXL')
            interval: ì¡°íšŒ ê¸°ê°„ (ì¼ìˆ˜)
            cache_hours: ìºì‹œ ìœ íš¨ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„, ê¸°ë³¸ 6ì‹œê°„)

        Returns:
            TickerData: DataFrame + ìºì‹œ ì •ë³´, ì‹¤íŒ¨ ì‹œ None
        """
        file_path = os.path.join(DATA_DIR, f"{ticker}.csv")
        timestamp_key = f"{ticker}_YF_DATA_TIMESTAMP"

        # ìºì‹œ í™•ì¸
        cache_info = self._get_cache_info(timestamp_key, cache_hours)
        if cache_info and os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, index_col=0)
                df.index = pd.to_datetime(df.index)
                logger.info(f"ğŸ“‚ ê¸°ì¡´ ë°ì´í„° ì‚¬ìš© ({ticker}, ê²½ê³¼: {cache_info.elapsed_hours:.1f}ì‹œê°„)")
                return TickerData(df=df, cache_info=cache_info)
            except Exception as e:
                logger.warning(f"âš ï¸ ìºì‹œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

        # ìƒˆë¡œìš´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (period ë°©ì‹ ì‚¬ìš©)
        # interval ì¼ìˆ˜ì— ë”°ë¼ ì ì ˆí•œ period ì„ íƒ
        if interval <= 30:
            period = "1mo"
        elif interval <= 90:
            period = "3mo"
        elif interval <= 180:
            period = "6mo"
        elif interval <= 365:
            period = "1y"
        elif interval <= 730:
            period = "2y"
        elif interval <= 1825:
            period = "5y"
        else:
            period = "max"

        try:
            df = yf.download(
                tickers=ticker,
                period=period,
                progress=False,
                group_by="ticker"
            )

            if df.empty:
                logger.error(f"âŒ [{ticker}] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ì—†ìŒ")
                return None

            # ë©€í‹° ì¸ë±ìŠ¤ ì²˜ë¦¬
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.droplevel(0)

            # CSV ì €ì¥ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë¡
            df.to_csv(file_path)
            cached_at = self._save_cache_timestamp(timestamp_key)
            logger.info(f"âœ… [{ticker}] ì €ì¥ ì™„ë£Œ: {file_path}")

            return TickerData(
                df=df,
                cache_info=CacheInfo(
                    cached_at=cached_at,
                    elapsed_hours=0.0,
                    is_from_cache=False
                )
            )

        except Exception as e:
            logger.error(f"{ticker} ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def clear_cache(self, ticker: str) -> bool:
        """
        íŠ¹ì • í‹°ì»¤ì˜ ìºì‹œ(íƒ€ì„ìŠ¤íƒ¬í”„) ì‚­ì œ

        Args:
            ticker: ìºì‹œ ì‚­ì œí•  í‹°ì»¤

        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        timestamp_key = f"{ticker}_YF_DATA_TIMESTAMP"
        try:
            self._key_store.delete(timestamp_key)
            logger.info(f"ğŸ—‘ï¸ [{ticker}] ìºì‹œ íƒ€ì„ìŠ¤íƒ¬í”„ ì‚­ì œ: {timestamp_key}")
            return True
        except Exception as e:
            logger.error(f"âŒ [{ticker}] ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            return False
